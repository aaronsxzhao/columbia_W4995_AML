{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uvpjs15BAHTI"
   },
   "source": [
    "**Homework 4 Spring 202**\n",
    "\n",
    "**Due Date** - **11/23/2022**\n",
    "\n",
    "Your Name -\n",
    "\n",
    "Your UNI - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iODY3WiAx01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_hCrDLfXUDR"
   },
   "source": [
    "# Part 1: Feed forward network from scratch!\n",
    "For this part, you are **not allowed** to use any library other than numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLYHZY7eA6Ha"
   },
   "source": [
    "In this part, you will will implement the forward pass and backward pass (i.e. the derivates of each parameter wrt to the loss) with the network image uploaded \n",
    "\n",
    "The weight matrix for the hidden layer is W1 and has bias b1.\n",
    "\n",
    "The weight matrix for the ouput layer is W2 and has bias b2.\n",
    "\n",
    "Activatation function is sigmoid for both hidden and output layer\n",
    "\n",
    "Loss function is the MSE loss\n",
    "\n",
    "Refer to the below dictionary for dimensions for each matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-KPjSLlCHgo"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # don't change this\n",
    "\n",
    "weights = {\n",
    "    'W1': np.random.randn(3, 2),\n",
    "    'b1': np.zeros(3),\n",
    "    'W2': np.random.randn(3),\n",
    "    'b2': 0,\n",
    "}\n",
    "X = np.random.rand(1000,2)\n",
    "Y = np.random.randint(low=0, high=2, size=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-unti7dVC1aK"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXUS2qzWC3iG"
   },
   "outputs": [],
   "source": [
    "#Implement the forward pass\n",
    "def forward_propagation(X, weights):\n",
    "    # Z1 -> output of the hidden layer before applying activation\n",
    "    # H -> output of the  hidden layer after applying activation\n",
    "    # Z2 -> output of the final layer before applying activation\n",
    "    # Y -> output of the final layer after applying activation\n",
    "    \n",
    "    Z1 = np.dot(X, weights['W1'].T)  + weights['b1']\n",
    "    H = sigmoid(Z1)\n",
    "    \n",
    "    # Z2 = \n",
    "    # Y =\n",
    "\n",
    "    return Y, Z2, H, Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhYNRcd9C7dt"
   },
   "outputs": [],
   "source": [
    "# Implement the backward pass\n",
    "# Y_T are the ground truth labels\n",
    "def back_propagation(X, Y_T, weights):\n",
    "    N_points = X.shape[0]\n",
    "    \n",
    "    # forward propagation\n",
    "    Y, Z2, H, Z1 = forward_propagation(X, weights)\n",
    "    L = (1/(2*N_points)) * np.sum(np.square(Y - Y_T))\n",
    "    \n",
    "    # back propagation\n",
    "    dLdY = 1/N_points * (Y - Y_T)\n",
    "    dLdZ2 = np.multiply(dLdY, (sigmoid(Z2)*(1-sigmoid(Z2))))\n",
    "    dLdW2 = np.dot(H.T, dLdZ2)\n",
    "    \n",
    "    # dLdb2 = \n",
    "    # dLdW1 = \n",
    "    # dLdb1 = \n",
    "    \n",
    "    gradients = {\n",
    "        'W1': dLdW1,\n",
    "        'b1': dLdb1,\n",
    "        'W2': dLdW2,\n",
    "        'b2': dLdb2,\n",
    "    }\n",
    "    \n",
    "    return gradients, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6PpD1xKG2kl"
   },
   "outputs": [],
   "source": [
    "gradients, L = back_propagation(X, Y, weights)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtezuPDhGxnY"
   },
   "outputs": [],
   "source": [
    "pp.pprint(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMlH7mtHDNcq"
   },
   "source": [
    "Your answers should be close to L = 0.133 and 'b1': array([ 0.00492, -0.000581, -0.00066]). You will be graded based on your implementation and outputs for L, W1, W2 b1, and b2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
